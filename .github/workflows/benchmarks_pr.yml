name: Continuous Benchmark

on:
  pull_request:

permissions: write-all

jobs:
  benchmark_cpu:
    name: CPU Pytest benchmark
    runs-on: ubuntu-20.04
    steps:
      - name: Who triggered this?
        run: |
          echo "Action triggered by ${{ github.event.pull_request.html_url }}"
      - name: Checkout
        uses: actions/checkout@v3
        with:
          fetch-depth: 50 # this is to make sure we obtain the target base commit
      - name: Python Setup
        uses: actions/setup-python@v4
        with:
          python-version: 3.8
      - name: Setup Environment
        run: |
          pip install -e .
          pip install pytest pytest-benchmark
      - name: Setup benchmarks
        run: |
          echo "BASE_SHA=$(echo ${{ github.event.pull_request.base.sha }} | cut -c1-8)" >> $GITHUB_ENV
          echo "HEAD_SHA=$(echo ${{ github.event.pull_request.head.sha }} | cut -c1-8)" >> $GITHUB_ENV
          echo "BASELINE_JSON=$(mktemp)" >> $GITHUB_ENV
          echo "CONTENDER_JSON=$(mktemp)" >> $GITHUB_ENV
          echo "PR_COMMENT=$(mktemp)" >>  $GITHUB_ENV
      - name: Run benchmarks
        run: |
          cd benchmarks/
          RUN_BENCHMARK="pytest --rank 0 --benchmark-columns ops --benchmark-min-rounds 100 --benchmark-max-time 2 --benchmark-json "
          git checkout ${{ github.event.pull_request.base.sha }}
          $RUN_BENCHMARK ${{ env.BASELINE_JSON }}
          git checkout ${{ github.event.pull_request.head.sha }}
          $RUN_BENCHMARK ${{ env.CONTENDER_JSON }}          
      - name: Publish results
        uses: apbard/pytest-benchmark-commenter@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          benchmark-file: ${{ env.BASELINE_JSON }}
          comparison-benchmark-file: ${{ env.CONTENDER_JSON }}
          benchmark-metrics: 'name,max,mean,ops'
          comparison-benchmark-metric: 'ops'
          comparison-higher-is-better: true
          comparison-threshold: 5
          benchmark-title: 'Result of CPU Benchmark Tests'
